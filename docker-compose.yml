services:
  spark-master:
    depends_on:
      minio:
        condition: service_started
    build: .
    container_name: spark-master
    command: >
      sh -c "/opt/spark/bin/spark-class org.apache.spark.deploy.master.Master -h spark-master &
      jupyter lab --ip=0.0.0.0 --port=8888 --no-browser --allow-root
      --notebook-dir=/opt/spark/work-dir/notebooks
      --ServerApp.token='' --ServerApp.password=''"
    ports:
      - "9090:8080" # UI do Spark Master
      - "4040:4040" # UI do Job
      - "7077:7077" # Porta de comunicação do Master com os Workers
      - "8888:8888" # Porta do Jupyter Lab
    volumes:
      - ./notebooks:/opt/spark/work-dir/notebooks
      - ./metastore_db:/opt/spark/work-dir/metastore_db # Persiste o banco de dados Derby
      - ./spark-defaults.conf:/opt/spark/conf/spark-defaults.conf # Monta as configurações padrão do Spark
    environment:
      - SPARK_CONF_DIR=/opt/spark/conf
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=false
      - SPARK_RPC_ENCRYPTION_ENABLED=false
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=false
      - SPARK_SSL_ENABLED=false      

  spark-worker-1:
    build: .
    container_name: spark-worker-1
    depends_on:
      - spark-master # O worker depende do master
    command: >
      /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker
      spark://spark-master:7077
    volumes:
      - ./spark-defaults.conf:/opt/spark/conf/spark-defaults.conf
    environment:
      - SPARK_CONF_DIR=/opt/spark/conf
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=12G
      - SPARK_WORKER_CORES=12
      - SPARK_RPC_AUTHENTICATION_ENABLED=false
      - SPARK_RPC_ENCRYPTION_ENABLED=false
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=false
      - SPARK_SSL_ENABLED=false

  spark-worker-2:
    build: .
    container_name: spark-worker-2
    depends_on:
      - spark-master # O worker depende do master
    command: >
      /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker
      spark://spark-master:7077
    volumes:
      - ./spark-defaults.conf:/opt/spark/conf/spark-defaults.conf
    environment:
      - SPARK_CONF_DIR=/opt/spark/conf
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=12G
      - SPARK_WORKER_CORES=12
      - SPARK_RPC_AUTHENTICATION_ENABLED=false
      - SPARK_RPC_ENCRYPTION_ENABLED=false
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=false
      - SPARK_SSL_ENABLED=false

  minio:
    image: minio/minio:RELEASE.2023-09-04T19-57-37Z
    container_name: minio
    command: server /data --console-address ":9001"
    ports:
      - "9000:9000" # Porta da API S3
      - "9001:9001" # Porta da UI (Console)
    volumes:
      - ./minio_data:/data # Mapeia uma pasta local para persistir os dados do MinIO
    environment:
      - MINIO_ROOT_USER=admin
      - MINIO_ROOT_PASSWORD=password
      - MINIO_DEFAULT_BUCKETS=database

networks:
  default:
    name: spark-network
