{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b05f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# 1. Criar a SparkSession com suporte ao Hive\n",
    "# As configurações já estão no ambiente, então o código fica limpo!\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"HiveMetastore-Test\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .enableHiveSupport()  # Habilita a integração com o Hive Metastore\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "print(\"Spark Session com Hive Metastore criada!\")\n",
    "\n",
    "# 2. Criar um DataFrame de exemplo\n",
    "data = [(\"Fusca\", 1970), (\"Opala\", 1980), (\"Chevette\", 1985)]\n",
    "columns = [\"modelo\", \"ano\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# 3. Salvar o DataFrame como uma tabela gerenciada\n",
    "# O Spark irá gerenciar os metadados (no PostgreSQL) e os dados (no MinIO)\n",
    "table_name = \"carros_classicos\"\n",
    "print(f\"Salvando DataFrame como tabela gerenciada: '{table_name}'\")\n",
    "\n",
    "df.write.mode(\"overwrite\").saveAsTable(table_name)\n",
    "\n",
    "print(\"Tabela salva com sucesso!\")\n",
    "\n",
    "# 4. Ler a tabela de volta usando spark.read.table()\n",
    "print(f\"\\nLendo a tabela '{table_name}' do catálogo:\")\n",
    "df_lido = spark.read.table(table_name)\n",
    "df_lido.show()\n",
    "\n",
    "# 5. Você pode listar as tabelas existentes\n",
    "print(\"\\nTabelas no catálogo:\")\n",
    "spark.catalog.listTables().show()\n",
    "\n",
    "# Você pode fechar este notebook, reiniciar o kernel ou até mesmo os contêineres.\n",
    "# Ao abrir um novo notebook e executar a célula 4 novamente, a tabela ainda estará lá!\n",
    "\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef80a1b-89f8-4a25-9490-acccfe550e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# 1. Inicie a SparkSession com suporte ao Hive\n",
    "# Lembre-se que todas as configurações já estão no ambiente, então o código fica limpo.\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Gerenciando-Databases\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .enableHiveSupport()  # Essencial para interagir com o catálogo do Hive\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "print(\"Spark Session com Hive Metastore criada!\")\n",
    "\n",
    "# 2. Crie um novo database chamado 'bronze_layer'\n",
    "# Usar 'IF NOT EXISTS' é uma boa prática para evitar erros se o database já existir.\n",
    "db_name = \"bronze_layer\"\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {db_name} COMMENT 'Database para dados brutos'\")\n",
    "\n",
    "print(f\"\\nDatabase '{db_name}' criado com sucesso!\")\n",
    "\n",
    "# 3. Verifique se o database foi criado listando todos os databases\n",
    "print(\"\\nDatabases existentes no catálogo:\")\n",
    "spark.sql(\"SHOW DATABASES\").show()\n",
    "\n",
    "# 4. Mude o contexto para o novo database\n",
    "spark.sql(f\"USE {db_name}\")\n",
    "print(f\"\\nContexto alterado para o database '{db_name}'.\")\n",
    "\n",
    "# 5. Crie uma tabela dentro do novo database\n",
    "# Os dados desta tabela serão armazenados em MinIO no caminho:\n",
    "# s3a://database/warehouse/bronze_layer.db/clientes_brutos\n",
    "data = [(\"1\", \"John Doe\", \"2024-10-26\"), (\"2\", \"Jane Smith\", \"2024-10-27\")]\n",
    "columns = [\"id_cliente\", \"nome_completo\", \"data_cadastro\"]\n",
    "df_clientes = spark.createDataFrame(data, columns)\n",
    "\n",
    "df_clientes.write.mode(\"overwrite\").saveAsTable(\"clientes_brutos\")\n",
    "\n",
    "print(\"\\nTabela 'clientes_brutos' criada dentro do database 'bronze_layer'.\")\n",
    "\n",
    "# 6. Liste as tabelas no database atual para confirmar\n",
    "print(f\"\\nTabelas no database '{db_name}':\")\n",
    "spark.sql(\"SHOW TABLES\").show()\n",
    "\n",
    "# Para acessar a tabela, você pode usar o nome qualificado: bronze_layer.clientes_brutos\n",
    "# ou, como já estamos usando o database, apenas o nome da tabela.\n",
    "print(\"\\nLendo dados da nova tabela:\")\n",
    "spark.read.table(\"clientes_brutos\").show()\n",
    "\n",
    "# Lembre-se de parar a sessão ao final\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9643aae-c8f3-4f07-91f6-aa596234b07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: javax.jdo.option.ConnectionURL\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/10/24 02:03:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session com Hive Metastore criada!\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# 1. Inicie a SparkSession com suporte ao Hive\n",
    "# Lembre-se que todas as configurações já estão no ambiente, então o código fica limpo.\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Gerenciando-Databases2\")\n",
    "    .master(\"spark://spark-master:7077\")\n",
    "    .enableHiveSupport()  # Essencial para interagir com o catálogo do Hive\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "print(\"Spark Session com Hive Metastore criada!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90103785-26c4-462f-be18-dc15045ec9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/24 02:03:45 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "25/10/24 02:03:55 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "25/10/24 02:03:55 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "25/10/24 02:04:00 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "25/10/24 02:04:00 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@172.18.0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Database 'bronze_layer' criado com sucesso!\n",
      "\n",
      "Contexto alterado para o database 'bronze_layer'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/24 02:04:01 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n",
      "[Stage 1:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+------------------+--------------------+------------+------------+\n",
      "|        CNPJ_FUNDO|    DT_REG|        CNPJ_ADMIN|               ADMIN|DT_INI_ADMIN|DT_FIM_ADMIN|\n",
      "+------------------+----------+------------------+--------------------+------------+------------+\n",
      "|00.000.432/0001-00|2005-03-31|33.868.597/0001-40|    CITIBANK DTVM SA|  2005-03-31|  2005-04-01|\n",
      "|00.000.432/0001-00|2005-03-31|61.472.676/0001-72|BANCO SANTANDER B...|  2005-04-01|  2006-11-21|\n",
      "|00.000.432/0001-00|2005-03-31|90.400.888/0001-42|BANCO SANTANDER (...|  2006-11-21|  2008-07-18|\n",
      "|00.000.744/0001-06|2005-01-13|33.066.408/0001-15|BANCO ABN AMRO RE...|  2005-01-01|  2006-06-30|\n",
      "|00.000.746/0001-03|2004-12-09|60.770.336/0001-65|BANCO ALFA DE INV...|  2004-11-29|        null|\n",
      "|00.000.756/0001-30|2005-03-21|17.192.451/0001-70| BANCO ITAUCARD S.A.|  2005-03-10|        null|\n",
      "|00.000.777/0001-56|2005-04-14|61.510.574/0001-02|SANTANDER S.A. CO...|  2005-03-31|  2006-12-13|\n",
      "|00.000.777/0001-56|2005-04-14|90.400.888/0001-42|BANCO SANTANDER (...|  2006-12-13|  2007-12-10|\n",
      "|00.000.777/0001-56|2005-04-14|73.159.642/0001-01|SANTANDER ASSET M...|  2007-12-10|  2011-01-01|\n",
      "|00.000.777/0001-56|2005-04-14|90.400.888/0001-42|BANCO SANTANDER (...|  2011-01-01|        null|\n",
      "|00.016.893/0001-63|2005-03-29|33.172.537/0001-98|BANCO J.P. MORGAN...|  2005-03-21|        null|\n",
      "|00.016.913/0001-04|2005-03-23|17.192.451/0001-70| BANCO ITAUCARD S.A.|  2005-03-09|        null|\n",
      "|00.016.917/0001-84|2005-01-17|61.230.165/0001-44|BANCO COMERCIAL E...|  2005-01-01|        null|\n",
      "|00.016.940/0001-79|2005-03-31|60.746.948/0001-12| BANCO BRADESCO S.A.|  2005-03-18|  2007-08-01|\n",
      "|00.016.940/0001-79|2005-03-31|01.638.542/0001-57|SAFRA DISTRIBUIDO...|  2007-08-01|        null|\n",
      "|00.016.962/0001-39|2005-04-01|33.172.537/0001-98|BANCO J.P. MORGAN...|  2005-03-21|        null|\n",
      "|00.016.991/0001-09|2005-04-05|17.192.451/0001-70| BANCO ITAUCARD S.A.|  2005-03-28|        null|\n",
      "|00.017.015/0001-62|2005-04-14|61.510.574/0001-02|SANTANDER S.A. CO...|  2005-03-31|  2006-09-15|\n",
      "|00.017.024/0001-53|2005-03-31|01.701.201/0001-89|KIRTON BANK S.A. ...|  2005-03-18|  2016-10-10|\n",
      "|00.017.024/0001-53|2005-03-31|60.746.948/0001-12| BANCO BRADESCO S.A.|  2016-10-10|        null|\n",
      "+------------------+----------+------------------+--------------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Crie um novo database chamado 'bronze_layer'\n",
    "# Usar 'IF NOT EXISTS' é uma boa prática para evitar erros se o database já existir.\n",
    "db_name = \"bronze_layer\"\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {db_name} COMMENT 'Database para dados brutos'\")\n",
    "\n",
    "print(f\"\\nDatabase '{db_name}' criado com sucesso!\")\n",
    "\n",
    "\n",
    "# 4. Mude o contexto para o novo database\n",
    "spark.sql(f\"USE {db_name}\")\n",
    "print(f\"\\nContexto alterado para o database '{db_name}'.\")\n",
    "\n",
    "# 5. Crie uma tabela dentro do novo database\n",
    "# Os dados desta tabela serão armazenados em MinIO no caminho:\n",
    "# s3a://database/warehouse/bronze_layer.db/clientes_brutos\n",
    "input_path = f\"s3a://raw/cad_fi_hist_admin.csv\"\n",
    "df_clientes = spark.read.csv(input_path, sep=\";\", header=True)\n",
    "df_clientes.show()\n",
    "# df_clientes.write.mode(\"overwrite\").saveAsTable(\"clientes_brutos\")\n",
    "\n",
    "# print(\"\\nTabela 'clientes_brutos' criada dentro do database 'bronze_layer'.\")\n",
    "\n",
    "# # 6. Liste as tabelas no database atual para confirmar\n",
    "# print(f\"\\nTabelas no database '{db_name}':\")\n",
    "# spark.sql(\"SHOW TABLES\").show()\n",
    "\n",
    "# # Para acessar a tabela, você pode usar o nome qualificado: bronze_layer.clientes_brutos\n",
    "# # ou, como já estamos usando o database, apenas o nome da tabela.\n",
    "# print(\"\\nLendo dados da nova tabela:\")\n",
    "# spark.read.table(\"clientes_brutos\").show()\n",
    "\n",
    "# # Lembre-se de parar a sessão ao final\n",
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6a2ad36-8db1-4483-b3a2-70b7f9f5d856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81192\n"
     ]
    }
   ],
   "source": [
    "print(df_clientes.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4864f5-c7cd-4331-80c6-8dbce59ad36d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
